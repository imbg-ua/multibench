import pandas as pd

import logging
# https://stackoverflow.com/questions/6290739/python-logging-use-milliseconds-in-time-format
logging.basicConfig(
    format='%(asctime)s.%(msecs)03d %(levelname)-5s %(name)s %(message)s',
    level=logging.INFO,
    datefmt='%Y-%m-%d %H:%M:%S')

from _config import config, ensure_config_ok
from fastlbp_runner import FastlbpBenchplanRecord, FastlbpRunner, FastlbpRunnerParams, fastlbp_benchplan_to_runner
from _scheduler import ParallelScheduler, SequentialScheduler, Job
from profiler import Profiler, make_profiling_runner
from _benchplan import read_fastlbp_benchplan


def main(bench_plan_path: str, avail_cpus: int, avail_mem_gb: int, check_interval: float = 10.0, print_interval: float = 60.0,
         prof_poll_interval:float = 5, prof_full_memory: bool = True, parallel: bool = False, 
         skip_ok: bool = True):
    """
    Execute a fastlbp benchmarking plan running a memory profiler for each job.

    @param bench_plan_path: str, path to a benchmarking plan (csv) generated by prepare_bench_plan.py
    @param avail_cpus: int, max number of (physical) cpus to use during benchmarking
    @param avail_mem: int, max number of RAM in GB to use during benchmarking
    @param check_interval: float, loop will update job status every check_interval seconds
    @param print_interval: float, loop will print status every print_interval seconds
    @param prof_poll_interval: float, memory profiler update interval in seconds
    @param prof_full_memory: bool, whether to use quick or full and slow memory info. USS is in full only.
    @param parallel: bool, default False. Shall we use sequential or parallel scheduler
    @param skip_ok: bool, default True. Shall we execute all runs, or only not runned yet? If true, skip all runs with status OK
    """
    # check type as well
    assert int(avail_cpus) >= 0, "avail_cpus should be int. did you forget '--'?"
    assert int(avail_mem_gb) >= 0, "avail_mem_gb should be int. did you forget '--'?"
    assert float(check_interval) >= 0, "check_interval should be float. did you forget '--'?"
    assert float(print_interval) >= 0, "print_interval should be float. did you forget '--'?"
    assert float(prof_poll_interval) >= 0, "prof_poll_interval should be float. did you forget '--'?"

    ensure_config_ok()
    
    logging.info(f"reading '{bench_plan_path}' with ensure_runnable=False")
    bp = read_fastlbp_benchplan(bench_plan_path)
    logging.info('================')
    logging.info(f"read {len(bp.all_runs)} rows")
    
    # print(str(bp.all_runs))

    profiler = Profiler(
        poll_interval_s=prof_poll_interval, 
        full_mem_info=prof_full_memory,
    )
    FastlbpProfilingRunner = make_profiling_runner(FastlbpRunner, profiler, results_dir=config.results_dir)

    if parallel:
        scheduler = ParallelScheduler(
            FastlbpProfilingRunner,
            avail_cpus,
            avail_mem_gb,
            check_interval,
            print_interval
        )
    else:
        scheduler = SequentialScheduler(
            FastlbpProfilingRunner,
            avail_cpus,
            avail_mem_gb,
            check_interval,
            print_interval
        )

    for benchplan_record in bp.all_runs:
        rec = benchplan_record
        if skip_ok and rec.result_ok == 'OK':
            continue
        scheduler.add_job(rec.ncpus, rec.approx_mem_usage_gb, params=fastlbp_benchplan_to_runner(rec))

    logging.info(f"job queue created. starting the profiling scheduler with {avail_cpus} CPUs and {avail_mem_gb} GB of memory")

    scheduler.run()
    logging.info("DONE!")
    

if __name__ == "__main__":
    import fire
    fire.Fire(main)
